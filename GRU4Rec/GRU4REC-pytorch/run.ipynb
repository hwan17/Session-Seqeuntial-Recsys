{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPHRqzmoNMx/JE7PxgseWRz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJktEFLrkwlo","executionInfo":{"status":"ok","timestamp":1691834319590,"user_tz":-540,"elapsed":23564,"user":{"displayName":"김소정 (김소정)","userId":"15493519997824979546"}},"outputId":"6f5d8b71-a140-4df0-f3d0-2f4b905de25f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir('/content/')\n","\n","import os.path\n","# orig_cwd = os.getcwd()\n","# os.chdir(os.path.dirname(os.path.abspath(__file__)))\n","path = '/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/GRU4Rec/GRU4REC-pytorch-master/GRU4REC-pytorch-master/'\n","os.chdir(path)\n","import numpy as np\n","import pandas as pd\n","import datetime as dt\n","import sys\n","import time\n","from collections import OrderedDict\n","import importlib\n","import importlib.util\n","import joblib\n","# os.chdir(orig_cwd)\n"]},{"cell_type":"markdown","source":["## DataPreprocess"],"metadata":{"id":"fOG7qJ3Nlu0A"}},{"cell_type":"code","source":["pd.read_csv(dataBefore,index_col =0)"],"metadata":{"id":"esmPCe-AH4FG","executionInfo":{"status":"ok","timestamp":1691833325068,"user_tz":-540,"elapsed":440,"user":{"displayName":"김소정 (김소정)","userId":"15493519997824979546"}},"outputId":"5470a176-da0b-434f-e5b8-9a69ac9096fb","colab":{"base_uri":"https://localhost:8080/","height":423}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       SessionID                      Time     ItemID\n","0              1  2014-04-07T10:51:09.277Z  214536502\n","1              1  2014-04-07T10:54:09.868Z  214536500\n","2              1  2014-04-07T10:54:46.998Z  214536506\n","3              1  2014-04-07T10:57:00.306Z  214577561\n","4              2  2014-04-07T13:56:37.614Z  214662742\n","...          ...                       ...        ...\n","99995      31812  2014-04-01T17:13:14.184Z  214662819\n","99996      31812  2014-04-01T17:13:49.017Z  214836765\n","99997      31812  2014-04-01T17:14:12.729Z  214836073\n","99998      31812  2014-04-01T17:14:48.288Z  214662819\n","99999      31812  2014-04-01T17:15:04.251Z  214843584\n","\n","[100000 rows x 3 columns]"],"text/html":["\n","\n","  <div id=\"df-4b69628f-3b89-4487-8b2c-73011afe881c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SessionID</th>\n","      <th>Time</th>\n","      <th>ItemID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2014-04-07T10:51:09.277Z</td>\n","      <td>214536502</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2014-04-07T10:54:09.868Z</td>\n","      <td>214536500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>2014-04-07T10:54:46.998Z</td>\n","      <td>214536506</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2014-04-07T10:57:00.306Z</td>\n","      <td>214577561</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>2014-04-07T13:56:37.614Z</td>\n","      <td>214662742</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>99995</th>\n","      <td>31812</td>\n","      <td>2014-04-01T17:13:14.184Z</td>\n","      <td>214662819</td>\n","    </tr>\n","    <tr>\n","      <th>99996</th>\n","      <td>31812</td>\n","      <td>2014-04-01T17:13:49.017Z</td>\n","      <td>214836765</td>\n","    </tr>\n","    <tr>\n","      <th>99997</th>\n","      <td>31812</td>\n","      <td>2014-04-01T17:14:12.729Z</td>\n","      <td>214836073</td>\n","    </tr>\n","    <tr>\n","      <th>99998</th>\n","      <td>31812</td>\n","      <td>2014-04-01T17:14:48.288Z</td>\n","      <td>214662819</td>\n","    </tr>\n","    <tr>\n","      <th>99999</th>\n","      <td>31812</td>\n","      <td>2014-04-01T17:15:04.251Z</td>\n","      <td>214843584</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100000 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b69628f-3b89-4487-8b2c-73011afe881c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-f30a4dfa-2555-4924-ab67-97794c7078ff\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f30a4dfa-2555-4924-ab67-97794c7078ff')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-f30a4dfa-2555-4924-ab67-97794c7078ff button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4b69628f-3b89-4487-8b2c-73011afe881c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4b69628f-3b89-4487-8b2c-73011afe881c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["aa = pd.read_csv('/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/data/yoochoose-data/kaggle/yoochoose-clicks_tiny.dat'\n",", sep=',', usecols=[0,1,2], dtype={0:np.int32, 1:str, 2:np.int64})\n","\n","aa.dtypes\n","aa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"NBpKq1ZmMQDj","executionInfo":{"status":"ok","timestamp":1691835955563,"user_tz":-540,"elapsed":7,"user":{"displayName":"김소정 (김소정)","userId":"15493519997824979546"}},"outputId":"07522f98-58f7-458d-afc8-734920aeeacc"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           0                         1          2\n","0          1  2014-04-07T10:51:09.277Z  214536502\n","1          1  2014-04-07T10:54:09.868Z  214536500\n","2          1  2014-04-07T10:54:46.998Z  214536506\n","3          1  2014-04-07T10:57:00.306Z  214577561\n","4          2  2014-04-07T13:56:37.614Z  214662742\n","...      ...                       ...        ...\n","99995  31812  2014-04-01T17:13:14.184Z  214662819\n","99996  31812  2014-04-01T17:13:49.017Z  214836765\n","99997  31812  2014-04-01T17:14:12.729Z  214836073\n","99998  31812  2014-04-01T17:14:48.288Z  214662819\n","99999  31812  2014-04-01T17:15:04.251Z  214843584\n","\n","[100000 rows x 3 columns]"],"text/html":["\n","\n","  <div id=\"df-2019a22e-64cb-4793-8636-50e1b804adb8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2014-04-07T10:51:09.277Z</td>\n","      <td>214536502</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2014-04-07T10:54:09.868Z</td>\n","      <td>214536500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>2014-04-07T10:54:46.998Z</td>\n","      <td>214536506</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2014-04-07T10:57:00.306Z</td>\n","      <td>214577561</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>2014-04-07T13:56:37.614Z</td>\n","      <td>214662742</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>99995</th>\n","      <td>31812</td>\n","      <td>2014-04-01T17:13:14.184Z</td>\n","      <td>214662819</td>\n","    </tr>\n","    <tr>\n","      <th>99996</th>\n","      <td>31812</td>\n","      <td>2014-04-01T17:13:49.017Z</td>\n","      <td>214836765</td>\n","    </tr>\n","    <tr>\n","      <th>99997</th>\n","      <td>31812</td>\n","      <td>2014-04-01T17:14:12.729Z</td>\n","      <td>214836073</td>\n","    </tr>\n","    <tr>\n","      <th>99998</th>\n","      <td>31812</td>\n","      <td>2014-04-01T17:14:48.288Z</td>\n","      <td>214662819</td>\n","    </tr>\n","    <tr>\n","      <th>99999</th>\n","      <td>31812</td>\n","      <td>2014-04-01T17:15:04.251Z</td>\n","      <td>214843584</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100000 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2019a22e-64cb-4793-8636-50e1b804adb8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-603a0f5e-935b-4a92-a7c2-18c40c204616\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-603a0f5e-935b-4a92-a7c2-18c40c204616')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-603a0f5e-935b-4a92-a7c2-18c40c204616 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2019a22e-64cb-4793-8636-50e1b804adb8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2019a22e-64cb-4793-8636-50e1b804adb8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Tue Sep 10 09:50:45 2019\n","@author: s-moh\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","import datetime\n","\n","dataBefore = '/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/data/yoochoose-data/kaggle/yoochoose-clicks_tiny.dat' #Path to Original Training Dataset \"Clicks\" File\n","dataTestBefore = '/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/data/yoochoose-data/kaggle/yoochoose-test_tiny.dat' #Path to Original Testing Dataset \"Clicks\" File\n","dataAfter ='/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/GRU4Rec/GRU4REC-pytorch-master/GRU4REC-pytorch-master/RecSys_Dataset_After_tiny/' #Path to Processed Dataset Folder\n","dayTime = 86400 #Validation Only one day = 86400 seconds\n","\n","def removeShortSessions(data):\n","    #delete sessions of length < 1\n","    sessionLen = data.groupby('SessionID').size() #group by sessionID and get size of each session\n","    data = data[np.in1d(data.SessionID, sessionLen[sessionLen > 1].index)]\n","    return data\n","\n","#Read Dataset in pandas Dataframe (Ignore Category Column)\n","train = pd.read_csv(dataBefore, sep=',', usecols=[0,1,2], dtype={0:np.int32, 1:str, 2:np.int64})\n","test = pd.read_csv(dataTestBefore, sep=',', usecols=[0,1,2], dtype={0:np.int32, 1:str, 2:np.int64})\n","train.columns = ['SessionID', 'Time', 'ItemID'] #Headers of dataframe\n","test.columns = ['SessionID', 'Time', 'ItemID'] #Headers of dataframe\n","train['Time']= train.Time.apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ').timestamp()) #Convert time objects to timestamp\n","test['Time'] = test.Time.apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ').timestamp()) #Convert time objects to timestamp\n","\n","#remove sessions of less than 2 interactions\n","train = removeShortSessions(train)\n","#delete records of items which appeared less than 5 times\n","itemLen = train.groupby('ItemID').size() #groupby itemID and get size of each item\n","train = train[np.in1d(train.ItemID, itemLen[itemLen > 4].index)]\n","#remove sessions of less than 2 interactions again\n","train = removeShortSessions(train)\n","\n","######################################################################################################3\n","'''\n","#Separate Data into Train and Test Splits\n","timeMax = data.Time.max() #maximum time in all records\n","sessionMaxTime = data.groupby('SessionID').Time.max() #group by sessionID and get the maximum time of each session\n","sessionTrain = sessionMaxTime[sessionMaxTime < (timeMax - dayTime)].index #training split is all sessions that ended before the last day\n","sessionTest  = sessionMaxTime[sessionMaxTime >= (timeMax - dayTime)].index #testing split is all sessions has records in the last day\n","train = data[np.in1d(data.SessionID, sessionTrain)]\n","test = data[np.in1d(data.SessionID, sessionTest)]\n","'''\n","#Delete records in testing split where items are not in training split\n","test = test[np.in1d(test.ItemID, train.ItemID)]\n","#Delete Sessions in testing split which are less than 2\n","test = removeShortSessions(test)\n","\n","#Convert To CSV\n","#print('Full Training Set has', len(train), 'Events, ', train.SessionID.nunique(), 'Sessions, and', train.ItemID.nunique(), 'Items\\n\\n')\n","#train.to_csv(dataAfter + 'recSys15TrainFull.txt', sep='\\t', index=False)\n","print('Testing Set has', len(test), 'Events, ', test.SessionID.nunique(), 'Sessions, and', test.ItemID.nunique(), 'Items\\n\\n')\n","test.to_csv(dataAfter + 'recSys15Test.txt', sep=',', index=False)\n","\n","######################################################################################################3\n","#Separate Training set into Train and Validation Splits\n","timeMax = train.Time.max()\n","sessionMaxTime = train.groupby('SessionID').Time.max()\n","sessionTrain = sessionMaxTime[sessionMaxTime < (timeMax - dayTime)].index #training split is all sessions that ended before the last 2nd day\n","sessionValid = sessionMaxTime[sessionMaxTime >= (timeMax - dayTime)].index #validation split is all sessions that ended during the last 2nd day\n","trainTR = train[np.in1d(train.SessionID, sessionTrain)]\n","trainVD = train[np.in1d(train.SessionID, sessionValid)]\n","#Delete records in validation split where items are not in training split\n","trainVD = trainVD[np.in1d(trainVD.ItemID, trainTR.ItemID)]\n","#Delete Sessions in testing split which are less than 2\n","trainVD = removeShortSessions(trainVD)\n","#Convert To CSV\n","print('Training Set has', len(trainTR), 'Events, ', trainTR.SessionID.nunique(), 'Sessions, and', trainTR.ItemID.nunique(), 'Items\\n\\n')\n","trainTR.to_csv(dataAfter + 'recSys15TrainOnly.txt', sep=',', index=False)\n","print('Validation Set has', len(trainVD), 'Events, ', trainVD.SessionID.nunique(), 'Sessions, and', trainVD.ItemID.nunique(), 'Items\\n\\n')\n","trainVD.to_csv(dataAfter + 'recSys15Valid.txt', sep=',', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zv47JFLDluWS","executionInfo":{"status":"ok","timestamp":1691836100911,"user_tz":-540,"elapsed":3986,"user":{"displayName":"김소정 (김소정)","userId":"15493519997824979546"}},"outputId":"6873cacc-e386-40f0-d122-8355159dc6b8"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing Set has 79483 Events,  20672 Sessions, and 2782 Items\n","\n","\n","Training Set has 70278 Events,  17794 Sessions, and 2933 Items\n","\n","\n","Validation Set has 13568 Events,  3416 Sessions, and 1771 Items\n","\n","\n"]}]},{"cell_type":"markdown","source":["## Model Run"],"metadata":{"id":"wtH4quIgmG5x"}},{"cell_type":"code","source":["import easydict\n","\n","args = easydict.EasyDict({\n","        \"hidden_size\": 100,\n","        \"num_layers\": 3,\n","        \"batch_size\": 50,\n","        \"dropout_input\": 0,\n","        \"dropout_hidden\": 0.5,\n","        \"n_epochs\": 5,\n","        \"k_eval\": 20,\n","        \"optimizer_type\":'Adagrad',\n","        \"final_act\": 'tanh',\n","        \"lr\": 0.01,\n","        \"weight_decay\" : 0,\n","        \"momentum\":0,\n","        \"eps\":1e-6,\n","        \"seed\":22,\n","        \"sigma\": None,\n","        \"embedding_dim\":-1,\n","        \"loss_type\": \"TOP1-max\",\n","        \"time_sort\":False,\n","        \"save_dir\":\"models\",\n","        \"data_folder\":'/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/GRU4Rec/GRU4REC-pytorch-master/GRU4REC-pytorch-master/RecSys_Dataset_After_tiny/',\n","        \"train_data\": 'recSys15TrainOnly.txt',\n","        'valid_data':'recSys15Valid.txt',\n","        'is_eval': None , # 'store_true',\n","        'load_model': None,\n","        \"checkpoint_dir\": \"checkpoint\"\n","})"],"metadata":{"id":"8Ry-oRcMtB2E","executionInfo":{"status":"ok","timestamp":1691836105994,"user_tz":-540,"elapsed":11,"user":{"displayName":"김소정 (김소정)","userId":"15493519997824979546"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["import argparse\n","import torch\n","import lib\n","import numpy as np\n","import os\n","import datetime\n","\n","\n","args.cuda = torch.cuda.is_available()\n","#use random seed defined\n","np.random.seed(args.seed)\n","torch.manual_seed(args.seed)\n","\n","\n","if args.cuda:\n","    torch.cuda.manual_seed(args.seed)\n","\n","#Write Checkpoints with arguments used in a text file for reproducibility\n","def make_checkpoint_dir():\n","    print(\"PARAMETER\" + \"-\"*10)\n","    now = datetime.datetime.now()\n","    S = '{:02d}{:02d}{:02d}{:02d}'.format(now.month, now.day, now.hour, now.minute)\n","    save_dir = os.path.join(args.checkpoint_dir, S)\n","    if not os.path.exists(args.checkpoint_dir):\n","        os.mkdir(args.checkpoint_dir)\n","\n","    if not os.path.exists(save_dir):\n","        os.mkdir(save_dir)\n","    args.checkpoint_dir = save_dir\n","    with open(os.path.join(args.checkpoint_dir, 'parameter.txt'), 'w') as f:\n","        for attr, value in sorted(args.__dict__.items()):\n","            print(\"{}={}\".format(attr.upper(), value))\n","            f.write(\"{}={}\\n\".format(attr.upper(), value))\n","    print(\"---------\" + \"-\"*10)\n","\n","#weight initialization if it was defined\n","def init_model(model):\n","    if args.sigma is not None:\n","        for p in model.parameters():\n","            if args.sigma != -1 and args.sigma != -2:\n","                sigma = args.sigma\n","                p.data.uniform_(-sigma, sigma)\n","            elif len(list(p.size())) > 1:\n","                sigma = np.sqrt(6.0 / (p.size(0) + p.size(1)))\n","                if args.sigma == -1:\n","                    p.data.uniform_(-sigma, sigma)\n","                else:\n","                    p.data.uniform_(0, sigma)\n","\n","\n","def main():\n","    print(\"Loading train data from {}\".format(os.path.join(args.data_folder, args.train_data)))\n","    print(\"Loading valid data from {}\".format(os.path.join(args.data_folder, args.valid_data)))\n","\n","    train_data = lib.Dataset(os.path.join(args.data_folder, args.train_data))\n","    valid_data = lib.Dataset(os.path.join(args.data_folder, args.valid_data), itemmap=train_data.itemmap)\n","    make_checkpoint_dir()\n","\n","    #set all the parameters according to the defined arguments\n","    input_size = len(train_data.items)\n","    hidden_size = args.hidden_size\n","    num_layers = args.num_layers\n","    output_size = input_size\n","    batch_size = args.batch_size\n","    dropout_input = args.dropout_input\n","    dropout_hidden = args.dropout_hidden\n","    embedding_dim = args.embedding_dim\n","    final_act = args.final_act\n","    loss_type = args.loss_type\n","    optimizer_type = args.optimizer_type\n","    lr = args.lr\n","    weight_decay = args.weight_decay\n","    momentum = args.momentum\n","    eps = args.eps\n","    n_epochs = args.n_epochs\n","    time_sort = args.time_sort\n","    #loss function\n","    loss_function = lib.LossFunction(loss_type=loss_type, use_cuda=args.cuda) #cuda is used with cross entropy only\n","    if not args.is_eval: #training\n","        #Initialize the model\n","        model = lib.GRU4REC(input_size, hidden_size, output_size, final_act=final_act,\n","                            num_layers=num_layers, use_cuda=args.cuda, batch_size=batch_size,\n","                            dropout_input=dropout_input, dropout_hidden=dropout_hidden, embedding_dim=embedding_dim)\n","        #weights initialization\n","        init_model(model)\n","        #optimizer\n","        optimizer = lib.Optimizer(model.parameters(), optimizer_type=optimizer_type, lr=lr,\n","                                  weight_decay=weight_decay, momentum=momentum, eps=eps)\n","        #trainer class\n","        trainer = lib.Trainer(model, train_data=train_data, eval_data=valid_data, optim=optimizer,\n","                              use_cuda=args.cuda, loss_func=loss_function, batch_size=batch_size, args=args)\n","        print('#### START TRAINING....')\n","        trainer.train(0, n_epochs - 1)\n","    else: #testing\n","        if args.load_model is not None:\n","            print(\"Loading pre-trained model from {}\".format(args.load_model))\n","            try:\n","                checkpoint = torch.load(args.load_model)\n","            except:\n","                checkpoint = torch.load(args.load_model, map_location=lambda storage, loc: storage)\n","            model = checkpoint[\"model\"]\n","            model.gru.flatten_parameters()\n","            evaluation = lib.Evaluation(model, loss_function, use_cuda=args.cuda, k = args.k_eval)\n","            loss, recall, mrr = evaluation.eval(valid_data, batch_size)\n","            print(\"Final result: recall = {:.2f}, mrr = {:.2f}\".format(recall, mrr))\n","        else:\n","            print(\"No Pretrained Model was found!\")\n","\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":993},"id":"eUDPcaZMlgsw","executionInfo":{"status":"error","timestamp":1691836125401,"user_tz":-540,"elapsed":19415,"user":{"displayName":"김소정 (김소정)","userId":"15493519997824979546"}},"outputId":"9b5a2a71-05a7-45b8-8934-9474c1213fe0"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading train data from /content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/GRU4Rec/GRU4REC-pytorch-master/GRU4REC-pytorch-master/RecSys_Dataset_After_tiny/recSys15TrainOnly.txt\n","Loading valid data from /content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/GRU4Rec/GRU4REC-pytorch-master/GRU4REC-pytorch-master/RecSys_Dataset_After_tiny/recSys15Valid.txt\n","PARAMETER----------\n","BATCH_SIZE=50\n","CHECKPOINT_DIR=checkpoint/08121028\n","CUDA=True\n","DATA_FOLDER=/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/GRU4Rec/GRU4REC-pytorch-master/GRU4REC-pytorch-master/RecSys_Dataset_After_tiny/\n","DROPOUT_HIDDEN=0.5\n","DROPOUT_INPUT=0\n","EMBEDDING_DIM=-1\n","EPS=1e-06\n","FINAL_ACT=tanh\n","HIDDEN_SIZE=100\n","IS_EVAL=None\n","K_EVAL=20\n","LOAD_MODEL=None\n","LOSS_TYPE=TOP1-max\n","LR=0.01\n","MOMENTUM=0\n","N_EPOCHS=5\n","NUM_LAYERS=3\n","OPTIMIZER_TYPE=Adagrad\n","SAVE_DIR=models\n","SEED=22\n","SIGMA=None\n","TIME_SORT=False\n","TRAIN_DATA=recSys15TrainOnly.txt\n","VALID_DATA=recSys15Valid.txt\n","WEIGHT_DECAY=0\n","-------------------\n","#### START TRAINING....\n","Start Epoch # 0\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▍  | 1046/1405 [00:04<00:01, 235.16it/s]\n"," 73%|███████▎  | 199/271 [00:00<00:00, 667.53it/s]\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-3e35b2b444eb>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-37-3e35b2b444eb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m                               use_cuda=args.cuda, loss_func=loss_function, batch_size=batch_size, args=args)\n\u001b[1;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#### START TRAINING....'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/GRU4Rec/GRU4REC-pytorch-master/GRU4REC-pytorch-master/lib/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_epoch, end_epoch, start_time)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start Epoch #'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/GRU4Rec/GRU4REC-pytorch-master/GRU4REC-pytorch-master/lib/evaluation.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, eval_data, batch_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mmean_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmean_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecalls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mmean_mrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmrrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmean_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_mrr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3432\u001b[0;31m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[1;32m   3433\u001b[0m                           out=out, **kwargs)\n\u001b[1;32m   3434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]}]},{"cell_type":"code","source":["def split_info(data: pd.DataFrame, status: str):\n","  print(f'*{status} Data Stats Info\\n'\n","        f'\\t Events'\n","\n","\n","\n","\n","        )"],"metadata":{"id":"X9YQ_n2AGoeg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["args"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txpasupr13Xy","executionInfo":{"status":"ok","timestamp":1691828586992,"user_tz":-540,"elapsed":264,"user":{"displayName":"김소정 (김소정)","userId":"15493519997824979546"}},"outputId":"1c0b4d3d-c054-4cb4-a4f7-882e928655c5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'hidden_size': 100,\n"," 'num_layers': 3,\n"," 'batch_size': 50,\n"," 'dropout_input': 0,\n"," 'dropout_hidden': 0.5,\n"," 'n_epochs': 5,\n"," 'k_eval': 20,\n"," 'optimizer_type': 'Adagrad',\n"," 'final_act': 'tanh',\n"," 'lr': 0.01,\n"," 'weight_decay': 0,\n"," 'momentum': 0,\n"," 'eps': 1e-06,\n"," 'seed': 22,\n"," 'sigma': None,\n"," 'embedding_dim': -1,\n"," 'loss_type': 'TOP1-max',\n"," 'time_sort': False,\n"," 'save_dir': 'models',\n"," 'data_folder': '/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/GRU4Rec/GRU4REC-pytorch-master/GRU4REC-pytorch-master/RecSys_Dataset_After/',\n"," 'train_data': 'recSys15TrainOnly.txt',\n"," 'valid_data': 'recSys15Valid.txt',\n"," 'is_eval': 'store_true',\n"," 'load_model': None,\n"," 'checkpoint_dir': 'checkpoint/08120821',\n"," 'cuda': False}"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["import argparse\n","import torch\n","import lib\n","import numpy as np\n","import os\n","import datetime\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--hidden_size', default=100, type=int) #Literature uses 100 / 1000 --> better is 100\n","parser.add_argument('--num_layers', default=3, type=int) #1 hidden layer\n","parser.add_argument('--batch_size', default=50, type=int) #50 in first paper and 32 in second paper\n","parser.add_argument('--dropout_input', default=0, type=float) #0.5 for TOP and 0.3 for BPR\n","parser.add_argument('--dropout_hidden', default=0.5, type=float) #0.5 for TOP and 0.3 for BPR\n","parser.add_argument('--n_epochs', default=5, type=int) #number of epochs (10 in literature)\n","parser.add_argument('--k_eval', default=20, type=int) #value of K durig Recall and MRR Evaluation\n","# parse the optimizer arguments\n","parser.add_argument('--optimizer_type', default='Adagrad', type=str) #Optimizer --> Adagrad is the best according to literature\n","parser.add_argument('--final_act', default='tanh', type=str) #Final Activation Function\n","parser.add_argument('--lr', default=0.01, type=float) #learning rate (Best according to literature 0.01 to 0.05)\n","parser.add_argument('--weight_decay', default=0, type=float) #no weight decay\n","parser.add_argument('--momentum', default=0, type=float) #no momentum\n","parser.add_argument('--eps', default=1e-6, type=float) #not used\n","parser.add_argument(\"-seed\", type=int, default=22, help=\"Seed for random initialization\") #Random seed setting\n","parser.add_argument(\"-sigma\", type=float, default=None, help=\"init weight -1: range [-sigma, sigma], -2: range [0, sigma]\") # weight initialization [-sigma sigma] in literature\n","\n","####### TODO: discover this ###########\n","parser.add_argument(\"--embedding_dim\", type=int, default=-1, help=\"using embedding\")\n","####### TODO: discover this ###########\n","\n","# parse the loss type\n","parser.add_argument('--loss_type', default='TOP1-max', type=str) #type of loss function TOP1 / BPR / TOP1-max / BPR-max\n","# etc\n","parser.add_argument('--time_sort', default=False, type=bool) #In case items are not sorted by time stamp\n","parser.add_argument('--model_name', default='GRU4REC-CrossEntropy', type=str)\n","parser.add_argument('--save_dir', default='models', type=str)\n","parser.add_argument('--data_folder', default='/content/drive/MyDrive/커리어/추천알고리즘_스터디/[2023 하반기]추천알고리즘 스터디/code/GRU4Rec/GRU4REC-pytorch-master/GRU4REC-pytorch-master/RecSys_Dataset_After_tiny/', type=str)\n","parser.add_argument('--train_data', default='recSys15TrainOnly.txt', type=str)\n","parser.add_argument('--valid_data', default='recSys15Valid.txt', type=str)\n","parser.add_argument(\"--is_eval\", action='store_true') #should be used during testing and eliminated during training\n","parser.add_argument('--load_model', default=None,  type=str)\n","parser.add_argument('--checkpoint_dir', type=str, default='checkpoint')\n","\n","# Get the arguments\n","args = parser.parse_args()\n","args.cuda = torch.cuda.is_available()\n","#use random seed defined\n","np.random.seed(args.seed)\n","torch.manual_seed(args.seed)\n","\n","\n","if args.cuda:\n","    torch.cuda.manual_seed(args.seed)\n","\n","#Write Checkpoints with arguments used in a text file for reproducibility\n","def make_checkpoint_dir():\n","    print(\"PARAMETER\" + \"-\"*10)\n","    now = datetime.datetime.now()\n","    S = '{:02d}{:02d}{:02d}{:02d}'.format(now.month, now.day, now.hour, now.minute)\n","    save_dir = os.path.join(args.checkpoint_dir, S)\n","    if not os.path.exists(args.checkpoint_dir):\n","        os.mkdir(args.checkpoint_dir)\n","\n","    if not os.path.exists(save_dir):\n","        os.mkdir(save_dir)\n","    args.checkpoint_dir = save_dir\n","    with open(os.path.join(args.checkpoint_dir, 'parameter.txt'), 'w') as f:\n","        for attr, value in sorted(args.__dict__.items()):\n","            print(\"{}={}\".format(attr.upper(), value))\n","            f.write(\"{}={}\\n\".format(attr.upper(), value))\n","    print(\"---------\" + \"-\"*10)\n","\n","#weight initialization if it was defined\n","def init_model(model):\n","    if args.sigma is not None:\n","        for p in model.parameters():\n","            if args.sigma != -1 and args.sigma != -2:\n","                sigma = args.sigma\n","                p.data.uniform_(-sigma, sigma)\n","            elif len(list(p.size())) > 1:\n","                sigma = np.sqrt(6.0 / (p.size(0) + p.size(1)))\n","                if args.sigma == -1:\n","                    p.data.uniform_(-sigma, sigma)\n","                else:\n","                    p.data.uniform_(0, sigma)\n","\n","\n","def main():\n","    print(\"Loading train data from {}\".format(os.path.join(args.data_folder, args.train_data)))\n","    print(\"Loading valid data from {}\".format(os.path.join(args.data_folder, args.valid_data)))\n","\n","    train_data = lib.Dataset(os.path.join(args.data_folder, args.train_data))\n","    valid_data = lib.Dataset(os.path.join(args.data_folder, args.valid_data), itemmap=train_data.itemmap)\n","    make_checkpoint_dir()\n","\n","    #set all the parameters according to the defined arguments\n","    input_size = len(train_data.items)\n","    hidden_size = args.hidden_size\n","    num_layers = args.num_layers\n","    output_size = input_size\n","    batch_size = args.batch_size\n","    dropout_input = args.dropout_input\n","    dropout_hidden = args.dropout_hidden\n","    embedding_dim = args.embedding_dim\n","    final_act = args.final_act\n","    loss_type = args.loss_type\n","    optimizer_type = args.optimizer_type\n","    lr = args.lr\n","    weight_decay = args.weight_decay\n","    momentum = args.momentum\n","    eps = args.eps\n","    n_epochs = args.n_epochs\n","    time_sort = args.time_sort\n","    #loss function\n","    loss_function = lib.LossFunction(loss_type=loss_type, use_cuda=args.cuda) #cuda is used with cross entropy only\n","    if not args.is_eval: #training\n","        #Initialize the model\n","        model = lib.GRU4REC(input_size, hidden_size, output_size, final_act=final_act,\n","                            num_layers=num_layers, use_cuda=args.cuda, batch_size=batch_size,\n","                            dropout_input=dropout_input, dropout_hidden=dropout_hidden, embedding_dim=embedding_dim)\n","        #weights initialization\n","        init_model(model)\n","        #optimizer\n","        optimizer = lib.Optimizer(model.parameters(), optimizer_type=optimizer_type, lr=lr,\n","                                  weight_decay=weight_decay, momentum=momentum, eps=eps)\n","        #trainer class\n","        trainer = lib.Trainer(model, train_data=train_data, eval_data=valid_data, optim=optimizer,\n","                              use_cuda=args.cuda, loss_func=loss_function, batch_size=batch_size, args=args)\n","        print('#### START TRAINING....')\n","        trainer.train(0, n_epochs - 1)\n","    else: #testing\n","        if args.load_model is not None:\n","            print(\"Loading pre-trained model from {}\".format(args.load_model))\n","            try:\n","                checkpoint = torch.load(args.load_model)\n","            except:\n","                checkpoint = torch.load(args.load_model, map_location=lambda storage, loc: storage)\n","            model = checkpoint[\"model\"]\n","            model.gru.flatten_parameters()\n","            evaluation = lib.Evaluation(model, loss_function, use_cuda=args.cuda, k = args.k_eval)\n","            loss, recall, mrr = evaluation.eval(valid_data, batch_size)\n","            print(\"Final result: recall = {:.2f}, mrr = {:.2f}\".format(recall, mrr))\n","        else:\n","            print(\"No Pretrained Model was found!\")\n","\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"id":"Eb4rmzNB0wy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UqYSqxPnr3tB"},"execution_count":null,"outputs":[]}]}